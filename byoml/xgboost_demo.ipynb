{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost example\n",
    "\n",
    "This notebook uses XGBoost 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data set\n",
    "\n",
    "We will create a dataset containing 7 features. The goal is to predict if the conditions are as expected, \n",
    "or an alarm should be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=2000, n_features=7, n_informative=5, n_redundant=2, weights=[0.8, 0.2],\n",
    "                           scale=[5, 5, 1, 1000, 200, 20, 10], shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heat</th>\n",
       "      <th>heat2</th>\n",
       "      <th>dust</th>\n",
       "      <th>light</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>nitrogen_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.214640</td>\n",
       "      <td>-3.107601</td>\n",
       "      <td>2.663515</td>\n",
       "      <td>-599.783123</td>\n",
       "      <td>67.133968</td>\n",
       "      <td>-40.880974</td>\n",
       "      <td>22.175197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.354232</td>\n",
       "      <td>14.506926</td>\n",
       "      <td>-0.832169</td>\n",
       "      <td>-1501.497188</td>\n",
       "      <td>-42.529406</td>\n",
       "      <td>8.094005</td>\n",
       "      <td>-13.488557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.380911</td>\n",
       "      <td>10.794966</td>\n",
       "      <td>1.566156</td>\n",
       "      <td>-1121.889667</td>\n",
       "      <td>-30.364312</td>\n",
       "      <td>-22.922713</td>\n",
       "      <td>10.072141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.396967</td>\n",
       "      <td>1.283805</td>\n",
       "      <td>1.444611</td>\n",
       "      <td>-827.627508</td>\n",
       "      <td>220.112282</td>\n",
       "      <td>-37.722183</td>\n",
       "      <td>14.348605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.324452</td>\n",
       "      <td>15.490906</td>\n",
       "      <td>1.597028</td>\n",
       "      <td>-673.973149</td>\n",
       "      <td>24.585876</td>\n",
       "      <td>-29.507437</td>\n",
       "      <td>19.428033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        heat      heat2      dust        light    humidity   pressure  \\\n",
       "0   3.214640  -3.107601  2.663515  -599.783123   67.133968 -40.880974   \n",
       "1  -0.354232  14.506926 -0.832169 -1501.497188  -42.529406   8.094005   \n",
       "2   4.380911  10.794966  1.566156 -1121.889667  -30.364312 -22.922713   \n",
       "3   6.396967   1.283805  1.444611  -827.627508  220.112282 -37.722183   \n",
       "4  13.324452  15.490906  1.597028  -673.973149   24.585876 -29.507437   \n",
       "\n",
       "   nitrogen_concentration  \n",
       "0               22.175197  \n",
       "1              -13.488557  \n",
       "2               10.072141  \n",
       "3               14.348605  \n",
       "4               19.428033  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = pd.DataFrame(X, columns=['heat', 'heat2', 'dust', 'light', 'humidity', 'pressure', 'nitrogen_concentration'])\n",
    "y_data = pd.DataFrame(y, columns=['ok'])\n",
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model + parameters and train\n",
    "\n",
    "We will create a model that outputs 1 or 0 for a class, not the probabilities. After saving the model and uploading it to the Waylay platform, send predict requests to the model will also result in 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective': 'binary:hinge'\n",
    "}\n",
    "num_round = 100  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dtest)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "def upload_model(model_name, description, upload_url, api_key, api_secret):\n",
    "    \n",
    "    zipfile_name = 'model.zip'\n",
    "    # Create a zip\n",
    "    with ZipFile(zipfile_name, 'w') as zipfile:\n",
    "       # Add multiple files to the zip\n",
    "       zipfile.write('model.bst')\n",
    "        \n",
    "    with open(zipfile_name, 'rb') as f:\n",
    "        upload_file = BytesIO(f.read())\n",
    "        \n",
    "    # upload to waylay\n",
    "    resp = requests.post(upload_url,\n",
    "                         files={\"file\": (zipfile_name, upload_file)},\n",
    "                         data={\"name\": model_name, \"framework\": \"xgboost\", \"description\": description},\n",
    "                         auth=HTTPBasicAuth(api_key, api_secret))\n",
    "\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model successfully uploaded'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.waylay.io/api/rest/#authentication\n",
    "api_key = 'your api key'\n",
    "api_secret = 'your api secret'\n",
    "byom_url = 'https://byoml.waylay.io/models'\n",
    "model_name = 'xgboost-demo-1'\n",
    "upload_model(\n",
    "    model_name, \n",
    "    'Model expecting 7 features and outputting the class it belongs to', \n",
    "    byom_url, \n",
    "    api_key, \n",
    "    api_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0.0, 0.0, 0.0, 0.0, 1.0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(byom_url + '/' + model_name + '/predict',\n",
    "              json = {\"instances\": X_test[:5].to_dict('records')},\n",
    "              auth=HTTPBasicAuth(api_key, api_secret)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed we get 1's and 0's as expected. If we need the probabilities, we can simply change the objective during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model that outputs probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set xgboost params\n",
    "param = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "num_round = 100  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03388389, 0.00636836, 0.07393802, 0.41373524, 0.59628487],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = bst.predict(dtest)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model successfully uploaded'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'xgboost-demo-2'\n",
    "upload_model(\n",
    "    model_name, \n",
    "    'Model expecting 7 features and outputting the probability it belongs to class 1', \n",
    "    byom_url, \n",
    "    api_key, \n",
    "    api_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0.03388388827443123,\n",
       "  0.0063683632761240005,\n",
       "  0.07393801957368851,\n",
       "  0.4137352406978607,\n",
       "  0.5962848663330078]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(byom_url + '/' + model_name + '/predict',\n",
    "              json = {\"instances\": X_test[:5].to_dict('records')},\n",
    "              auth=HTTPBasicAuth(api_key, api_secret)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed we get the same probabilities as our model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the XGBClassifier\n",
    "Instead of directly using a booster we can also use the XGBClassifier as is shown in the example below. Keep in mind although the predict method will return 1's and 0's, the uploaded model will output the probabilities as the underlying Booster object is used. This can again be \"solved\", by using the `binary:hinge` objective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('model.bst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model successfully uploaded'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'xgboost-demo-3'\n",
    "\n",
    "upload_model(\n",
    "    model_name, \n",
    "    'Model expecting 7 features and outputting the probability it belongs to class 1', \n",
    "    byom_url, \n",
    "    api_key, \n",
    "    api_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0.03388388827443123,\n",
       "  0.0063683632761240005,\n",
       "  0.07393801957368851,\n",
       "  0.4137352406978607,\n",
       "  0.5962848663330078]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(byom_url + '/' + model_name + '/predict',\n",
    "              json = {\"instances\": X_test[:5].to_dict('records')},\n",
    "              auth=HTTPBasicAuth(api_key, api_secret)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed in this case the model output and uploaded model output are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json payload\n",
    "\n",
    "All examples above use named input. This is possible if you correctly name your features in the pandas.DataFrame or DMatrix. \n",
    "The value belonging to the `instances` key in the json payload is a list of dicts. This is a readable and clear way to represent the data you are sending to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [{'heat': 5.183476657027435,\n",
       "   'heat2': 6.198644531071017,\n",
       "   'dust': -1.219976895450299,\n",
       "   'light': 107.67054117584141,\n",
       "   'humidity': -465.49147434265274,\n",
       "   'pressure': 38.75732300448353,\n",
       "   'nitrogen_concentration': 4.022103340261581},\n",
       "  {'heat': 3.5709824385447964,\n",
       "   'heat2': 8.125604685184385,\n",
       "   'dust': -2.478955463265079,\n",
       "   'light': -2604.0885807693817,\n",
       "   'humidity': -373.7320669125462,\n",
       "   'pressure': 36.35173333809967,\n",
       "   'nitrogen_concentration': -7.037420725073713},\n",
       "  {'heat': 0.7194705291230102,\n",
       "   'heat2': 2.1881363868111894,\n",
       "   'dust': 0.5056000888381222,\n",
       "   'light': -511.6016770257128,\n",
       "   'humidity': 379.57152848272784,\n",
       "   'pressure': -29.93469296853077,\n",
       "   'nitrogen_concentration': -3.2944090003344955},\n",
       "  {'heat': -0.7485073820496291,\n",
       "   'heat2': 0.5923026689001221,\n",
       "   'dust': -0.5468724982274361,\n",
       "   'light': 1515.0726572135725,\n",
       "   'humidity': -52.18054740864142,\n",
       "   'pressure': 17.549078297445277,\n",
       "   'nitrogen_concentration': -4.908612515506896},\n",
       "  {'heat': 1.834596974045903,\n",
       "   'heat2': -13.159726910751811,\n",
       "   'dust': -0.006244944028804933,\n",
       "   'light': -1507.0812759276143,\n",
       "   'humidity': 61.24565650426958,\n",
       "   'pressure': -15.100126382881927,\n",
       "   'nitrogen_concentration': 11.40206238086906}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"instances\": X_test[:5].to_dict('records')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending data to the model this way is convenient as you do not have to know the order of the features. If you would just use numpy arrays for training without naming anything, you can also call your model in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.183476657027435,\n",
       "  6.198644531071017,\n",
       "  -1.219976895450299,\n",
       "  107.67054117584141,\n",
       "  -465.49147434265274,\n",
       "  38.75732300448353,\n",
       "  4.022103340261581],\n",
       " [3.5709824385447964,\n",
       "  8.125604685184385,\n",
       "  -2.478955463265079,\n",
       "  -2604.0885807693817,\n",
       "  -373.7320669125462,\n",
       "  36.35173333809967,\n",
       "  -7.037420725073713],\n",
       " [0.7194705291230102,\n",
       "  2.1881363868111894,\n",
       "  0.5056000888381222,\n",
       "  -511.6016770257128,\n",
       "  379.57152848272784,\n",
       "  -29.93469296853077,\n",
       "  -3.2944090003344955],\n",
       " [-0.7485073820496291,\n",
       "  0.5923026689001221,\n",
       "  -0.5468724982274361,\n",
       "  1515.0726572135725,\n",
       "  -52.18054740864142,\n",
       "  17.549078297445277,\n",
       "  -4.908612515506896],\n",
       " [1.834596974045903,\n",
       "  -13.159726910751811,\n",
       "  -0.006244944028804933,\n",
       "  -1507.0812759276143,\n",
       "  61.24565650426958,\n",
       "  -15.100126382881927,\n",
       "  11.40206238086906]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = X_test[:5].values.tolist()\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [0.03388388827443123,\n",
       "  0.0063683632761240005,\n",
       "  0.07393801957368851,\n",
       "  0.4137352406978607,\n",
       "  0.5962848663330078]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(byom_url + '/' + model_name + '/predict',\n",
    "              json = {\"instances\": instances},\n",
    "              auth=HTTPBasicAuth(api_key, api_secret)).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete created models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model successfully deleted'}\n",
      "{'message': 'Model successfully deleted'}\n",
      "{'message': 'Model successfully deleted'}\n"
     ]
    }
   ],
   "source": [
    "models = ['xgboost-demo-1', 'xgboost-demo-2', 'xgboost-demo-3']\n",
    "for model in models:\n",
    "    print(\n",
    "        requests.delete(byom_url + '/' + model, \n",
    "                        auth=HTTPBasicAuth(api_key, api_secret)).json()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
